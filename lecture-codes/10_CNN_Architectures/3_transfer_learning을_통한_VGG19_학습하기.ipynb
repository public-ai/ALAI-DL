{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0BBiGLQkG58",
    "colab_type": "text"
   },
   "source": [
    "╔══<i><b>Alai-DeepLearning</b></i>════════════════════════════╗\n",
    "###  &nbsp;&nbsp; **✎&nbsp;&nbsp;Week 10. CNN Architectures**\n",
    "# Section 3. Transfer Learning을 통한 VGG19 학습하기\n",
    "\n",
    "### _Objective_\n",
    "\n",
    "1. 이전 Section에서 학습한 VGG 11을 통해 VGG 19를 학습시키도록 하겠습니다.\n",
    "  \n",
    "╚═════════════════════════════════════════╝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "cxGNXuockG59",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "!pip install tensorboardcolab\n",
    "import tensorboardcolab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPQJ3xgEkG6A",
    "colab_type": "text"
   },
   "source": [
    "## Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "cHUcrXWpkG6A",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import numpy as np    \n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPB4Btt4kG6C",
    "colab_type": "text"
   },
   "source": [
    "## 예제 데이터셋) CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "VptTA3s_kG6D",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.cifar100 import load_data\n",
    "(train_x, train_y), (test_x, test_y) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JMpmTtkgkG6E",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    # 데이터셋을 배치 단위로 처리할 수 있도록 도와주는 Class\n",
    "    #fix me #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "PIK8aetkkG6G",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# 이미지 시각화하기\n",
    "train_set = Dataset(train_x,train_y)\n",
    "test_set = Dataset(test_x, test_y)\n",
    "num_sample = 5\n",
    "\n",
    "sample_x, sample_y = train_set.next_batch(num_sample)\n",
    "\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "axes = fig.subplots(1,num_sample)\n",
    "\n",
    "for ax, image, label in zip(axes, sample_x, sample_y):\n",
    "    ax.set_title(label)\n",
    "    ax.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_sQN8o_kG6I",
    "colab_type": "text"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# \\[ 1. VGG 19 학습하기 \\]\n",
    "---\n",
    "---\n",
    "\n",
    "> *VGG Network가 당시에 최고의 성능을 낼 수 있었던 이유는 바로 Layer의 깊이에 있습니다.*<br>\n",
    "> *VGG Network는 Scratch부터 학습하는 방식이 아닌, 우선 적은 층으로 학습한 후, Transfer Learning을 통해, 깊게 학습시키는 방식으로 진행되었습니다*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsPzZAw7kG6I",
    "colab_type": "text"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1. Network 구성하기\n",
    "----\n",
    "\n",
    "![Imgur](https://i.imgur.com/YeoF2AE.png)\n",
    "\n",
    "* ImageNet에서의 Hyper-Parameter를 바로 적용하기에 몇가지 수정이 필요합니다.<br>\n",
    "* 이미지의 크기가 imagenet에 비해 8배정도 작기 때문에, 첫 두개의 max-pooling layer를 생략하였습니다.<br>\n",
    "* Class 수가 1000개에서 100개로 줄었기 때문에, Fully Connected Layer의 노드 수를 4096에서 1024로 줄였습니다.\n",
    "* 이미지의 복잡도도 좀 더 작다고 판단되기 때문에, Convolution Filter의 갯수들을 모두 1/2로 줄였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "1SXOgjh-kG6J",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "input_shape = (None,32,32,3) # Cifar-100 이미지 크기\n",
    "num_classes = 100 # cifar-100 클래스 수\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    images = #fix me#\n",
    "    labels = #fix me#\n",
    "    is_train = #fix me#\n",
    "    lr = #fix me#\n",
    "    \n",
    "    with tf.variable_scope(\"preprocess\"):\n",
    "        vgg_mean = #fix me#\n",
    "        x = #fix me#\n",
    "    \n",
    "    with tf.variable_scope('VGGBlock-1'):\n",
    "        #fix me #\n",
    "    # 이미지가 224에 비해 매우 작기 때문에, maxpooling Layer를 생략하였습니다.\n",
    "        \n",
    "    with tf.variable_scope('VGGBlock-2'):\n",
    "        #fix me #\n",
    "        \n",
    "    # 이미지가 224에 비해 매우 작기 때문에, maxpooling Layer를 생략하였습니다.            \n",
    "\n",
    "    with tf.variable_scope('VGGBlock-3'):\n",
    "        #fix me #\n",
    "        \n",
    "        \n",
    "    with tf.variable_scope('VGGBlock-4'):\n",
    "        #fix me #\n",
    "        \n",
    "                \n",
    "    with tf.variable_scope('VGGBlock-5'):\n",
    "        #fix me #\n",
    "    with tf.variable_scope('FC'):\n",
    "        #fix me #\n",
    "        \n",
    "    \n",
    "    weight_decay = 5e-4\n",
    "    with tf.variable_scope(\"losses\"):\n",
    "        sce = #fix me #\n",
    "        l2_loss = #fix me #\n",
    "        loss = #fix me #\n",
    "    loss = tf.identity(loss, name='loss')    \n",
    "    \n",
    "    momentum = 0.9\n",
    "    with tf.variable_scope(\"optimizer\"):\n",
    "        global_step = #fix me #\n",
    "        train_op = #fix me #\n",
    "    with tf.variable_scope('metrics'):\n",
    "        top_5, top_5_op = tf.metrics.mean(#fix me #)\n",
    "        top_1, top_1_op = tf.metrics.mean(#fix me #)\n",
    "        metric_loss, loss_op = tf.metrics.mean(loss)\n",
    "    \n",
    "    # Total과 Count를 reset하는 연산자\n",
    "    metric_init_op = tf.group(#fix me #)\n",
    "    # Total과 Count를 갱신하는 연산자\n",
    "    metric_update_op = tf.group(#fix me #)\n",
    "\n",
    "    top_5 = tf.identity(top_5, name='top5_acc')\n",
    "    top_1 = tf.identity(top_1, name='top1_acc')\n",
    "    metric_loss = tf.identity(metric_loss, name='metric_loss')            \n",
    "    \n",
    "    tf.summary.scalar('top5_accuracy', top_5)\n",
    "    tf.summary.scalar('top1_accuracy', top_1)\n",
    "    tf.summary.scalar('losses', metric_loss)    \n",
    "    merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true,
    "id": "3VU2-xSskG6L",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "show_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZbVJDZbkG6M",
    "colab_type": "text"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 2. Weight Transfer 적용하기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLsMsAbkkG6N",
    "colab_type": "text"
   },
   "source": [
    "### (1) weights가 저장된 구글 드라이브와 연동하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "o5nCjE12kG6O",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# 구글 드라이브랑 연동하기\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "27RieyHekG6Q",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# vgg 폴더를 만들어 모델 가져오기\n",
    "!mkdir vgg/\n",
    "!cp gdrive/My\\ Drive/vgg/* vgg/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e07mIY1xkG6S",
    "colab_type": "text"
   },
   "source": [
    "### (2) 필요한 weight들을 지정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Xt0dwWRxkG6T",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "b1_ws = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                             \"(VGGBlock-1/conv1)\")\n",
    "b2_ws = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                             \"(VGGBlock-2/conv1)\")\n",
    "b3_ws = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                             \"VGGBlock-3/(conv1|conv2)\")\n",
    "fc_ws = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                             \"FC/\")\n",
    "\n",
    "transfer_weights = b1_ws + b2_ws + b3_ws + fc_ws\n",
    "transfer_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TERV2pVVkG6V",
    "colab_type": "text"
   },
   "source": [
    "### (3) 필요한 Weight들을 저장한 ckpt로부터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5T7RbrakG6V",
    "colab_type": "text"
   },
   "source": [
    "학습한 모델은 아래와 같이 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true,
    "id": "3bLpZsy0kG6W",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # 가중치 초기화\n",
    "    sess = tf.Session(graph=graph)\n",
    "    saver = tf.train.Saver(var_list=transfer_weights)\n",
    "    saver.restore(sess, \"./vgg/vgg11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAAYXuBgkG6Y",
    "colab_type": "text"
   },
   "source": [
    "### (4) 나머지 Weight들을 초기화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Q3TUKnUXkG6Z",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with tf.variable_scope('initialization'):\n",
    "        # 모든 variable 가져옴        \n",
    "        global_vars = tf.global_variables()\n",
    "\n",
    "        # Variable이 초기화되었는지 안되었는지 확인\n",
    "        is_not_initialized = sess.run(\n",
    "            [tf.is_variable_initialized(var) for var in global_vars])\n",
    "\n",
    "        # Variable 중 초기화되지 않은것만 가져옴\n",
    "        not_initialized_vars = [v for (v, f) in\n",
    "                                zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "        # 초기화되지 않은 것이 있으면, 초기화시킴\n",
    "        if len(not_initialized_vars):\n",
    "            sess.run(tf.variables_initializer(not_initialized_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z88G6XwokG6d",
    "colab_type": "text"
   },
   "source": [
    "위의 과정이 까다롭다면, 먼저 모델을 초기화한 후, Transfer weight들을 덮어씌우는 방식으로도<br>\n",
    "진행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "FvN2PKVMkG6f",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # 가중치 초기화\n",
    "    sess = tf.Session(graph=graph)\n",
    "    sess.run([tf.global_variables_initializer(),\n",
    "              tf.local_variables_initializer()])\n",
    "    saver = tf.train.Saver(var_list=transfer_weights)\n",
    "    saver.restore(sess, \"./vgg/vgg11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-B-Sa-2kG6h",
    "colab_type": "text"
   },
   "source": [
    "### (5) Tensorboard 세팅하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "flxos0iGkG6i",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# LOG PATH Setting\n",
    "LOG_DIR = \"./log\"\n",
    "if os.path.exists(LOG_DIR):\n",
    "    shutil.rmtree(LOG_DIR)\n",
    "os.makedirs(LOG_DIR,exist_ok=True)\n",
    "\n",
    "tbc = tensorboardcolab.TensorBoardColab(graph_path=LOG_DIR)\n",
    "\n",
    "train_writer = tf.summary.FileWriter(LOG_DIR+\"/train\", graph)\n",
    "test_writer = tf.summary.FileWriter(LOG_DIR+\"/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihLF_fTEkG6k",
    "colab_type": "text"
   },
   "source": [
    "### (6) 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "NXJwsEsZkG6l",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "num_epoch = 20\n",
    "num_batch = 128\n",
    "num_data = len(train_set)\n",
    "\n",
    "for epoch in range(#fix me#):\n",
    "    # Fitting Model  \n",
    "    for step in tqdm(range(#fix me#)):\n",
    "        batch_x, batch_y = train_set.next_batch(num_batch)\n",
    "        sess.run(train_op,#fix me #)\n",
    "    # 데이터 셋 섞어주기\n",
    "    train_set.shuffle()\n",
    "    \n",
    "    # Summarize training process\n",
    "    sess.run(metric_init_op)\n",
    "    for step in range(0,len(train_set)//1000):\n",
    "        # 1000개씩 나누어서 metric을 계산합니다.\n",
    "        batch_x = #fix me#\n",
    "        batch_y = #fix me#\n",
    "        sess.run(#fix me#)\n",
    "    \n",
    "    summary, top_1_value,top_5_value, loss_value = sess.run(#fix me#)\n",
    "    \n",
    "    print(\"[{:3d} epoch] TRAIN TOP-1 ACC : {:2.2f}% | TOP-5 ACC : {:2.2f}% | LOSS : {:.3f}\"\n",
    "          .format(epoch, top_1_value,top_5_value,loss_value))\n",
    "    train_writer.add_summary(summary, global_step.eval(sess))\n",
    "\n",
    "    sess.run(metric_init_op)\n",
    "    for step in range(len(test_set)//1000):\n",
    "        batch_x = #fix me #\n",
    "        batch_y = #fix me #\n",
    "        sess.run(#fix me #)\n",
    "        \n",
    "    summary, top_1_value,top_5_value, loss_value = sess.run(#fix me #)\n",
    "    print(\"[{:3d} epoch] TEST TOP-1 ACC : {:2.2f}% | TOP-5 ACC : {:2.2f}% | LOSS : {:.3f}\"\n",
    "          .format(epoch, top_1_value,top_5_value,loss_value))\n",
    "    test_writer.add_summary(summary, global_step.eval(sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKDvYCN8kG6n",
    "colab_type": "text"
   },
   "source": [
    "#  \n",
    "\n",
    "---\n",
    "\n",
    "    Copyright(c) 2019 by Public AI. All rights reserved.<br>\n",
    "    Writen by PAI, SangJae Kang ( rocketgrowthsj@publicai.co.kr )  last updated on 2019/05/07\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "3. transfer learning을 통한 VGG19 학습하기.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}