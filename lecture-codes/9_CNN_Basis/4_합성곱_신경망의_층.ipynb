{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCx5BXUfno3b",
    "colab_type": "text"
   },
   "source": [
    " ╔══<i><b>Alai-DeepLearning</b></i>════════════════════════════╗\n",
    "###  &nbsp;&nbsp; **✎&nbsp;&nbsp;Week 9. CNN Basis**\n",
    "# Section 4. 합성곱 층(Convolution Layer)의 구조\n",
    "\n",
    "### _Objective_\n",
    "1. 합성곱 층은 이전에 배운 DNN와 비슷하게, Logit을 계산하는 부분과 활성화 함수를 계산하는 부분으로 나누어집니다. <br>\n",
    "2. 고전 CNN 모델을 살펴보면서, CNN의 구조에 대해 배워보도록 하겠습니다.  <br> \n",
    "  \n",
    "╚═════════════════════════════════════════╝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "6lVIf6B-no3d",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57fjO_Vgno3f",
    "colab_type": "text"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "# \\[ 1. 합성곱 층의 구조 \\]\n",
    "\n",
    "----\n",
    "----\n",
    " \n",
    "> *합성곱 연산도 이전의 Fully Connected Layed와 마찬가지로, Bias가 존재합니다.*<br>\n",
    "> *합성곱 연산 이후 활성화 함수를 넣음으로써, 비선형성을 증대시킵니다.*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9lI9zvPno3g",
    "colab_type": "text"
   },
   "source": [
    "## 1. 합성곱 연산에 Bias 추가하기\n",
    "---\n",
    "\n",
    "* 각 필터 별로 Bias를 추가함으로써, 필터 별 Threshold을 학습할 수 있게 됩니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRk7XJrKno3g",
    "colab_type": "text"
   },
   "source": [
    "### (1) 3차원 데이터 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Jt2ocRlpno3h",
    "colab_type": "code",
    "outputId": "956711af-c005-4c21-ddb8-a541a89f7577",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력값의 형태 (H, W, C) :(4,4,3)\n"
     ]
    }
   ],
   "source": [
    "in0 = np.array([\n",
    "    [1,4,2,0],\n",
    "    [2,3,1,1],\n",
    "    [3,1,3,2],\n",
    "    [4,2,1,4],\n",
    "])\n",
    "in1 = np.array([\n",
    "    [1,7,0,2],\n",
    "    [3,2,1,1],\n",
    "    [0,7,5,1],\n",
    "    [0,1,5,2],    \n",
    "])\n",
    "in2 = np.array([\n",
    "    [1,5,1,5],\n",
    "    [3,2,1,9],\n",
    "    [4,2,2,7],\n",
    "    [1,2,1,9],\n",
    "])\n",
    "inputs = np.stack(#fix me #)\n",
    "print(\"입력값의 형태 (H, W, C) :({},{},{})\".format(*inputs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0rYUyRdno3l",
    "colab_type": "text"
   },
   "source": [
    "### (2) Filter 와 Bias 구성하기\n",
    "* 필터 별로 독립적인 Bias가 존재합니다. 필터가  $(n_f,h_f,w_f,c_{in})$로 구성되어 있을 때, Bias는 $n_f$개 만큼 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "foe3ax4qno3m",
    "colab_type": "code",
    "outputId": "9602c989-92cd-45c2-f106-f008db36d1f2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter의 형태 (N, H, W, C) : (2,3,3,3)\n"
     ]
    }
   ],
   "source": [
    "filter_1 = np.array([\n",
    "    [[2,0,1],[0,1,2],[1,0,2]],\n",
    "    [[0,1,3],[2,1,3],[4,1,2]],\n",
    "    [[3,2,1],[2,2,3],[0,0,1]]])\n",
    "filter_2 = np.array([\n",
    "    [[4,0,1],[0,0,4],[0,3,2]],\n",
    "    [[6,1,2],[3,5,1],[2,3,2]],\n",
    "    [[1,4,1],[1,3,1],[2,1,0]]])\n",
    "\n",
    "filters = np.stack(#fix me #)\n",
    "print(\"Filter의 형태 (N, H, W, C) : ({},{},{},{})\".format(*filters.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "cpREXfakno3o",
    "colab_type": "code",
    "outputId": "1b7fc867-1c94-48f0-e971-262b574d3b7d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias의 갯수 : 2\n"
     ]
    }
   ],
   "source": [
    "bias = np.array([-100,20])\n",
    "print(\"bias의 갯수 : {}\".format(len(bias)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsjPfKC-no3r",
    "colab_type": "text"
   },
   "source": [
    "### (3) 합성곱 연산 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "fXhz9xEYno3s",
    "colab_type": "code",
    "outputId": "bd2a8f8c-614d-4267-9d7e-9d1e4d2ceb88",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 86., 149.],\n",
       "        [ 68., 174.]],\n",
       "\n",
       "       [[ 91., 160.],\n",
       "        [ 86., 152.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 합성곱 연산 진행하기\n",
    "outputs = np.zeros(#fix me#)\n",
    "for i in range(#fix me#):\n",
    "    for j in range(#fix me#):\n",
    "        for k in range(#fix me #):\n",
    "            result = #fix me#\n",
    "            outputs[#fix me#] = result\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "8JCOzvg3no3w",
    "colab_type": "code",
    "outputId": "862eb966-8e30-468a-d47a-993a713997ee",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-14., 169.],\n",
       "        [-32., 194.]],\n",
       "\n",
       "       [[ -9., 180.],\n",
       "        [-14., 172.]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias를 더해줌\n",
    "outputs = #fix me#\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLYJwlwLno3z",
    "colab_type": "text"
   },
   "source": [
    "<br>\n",
    "## 2. 합성곱 연산 후 활성화함수 추가하기\n",
    "---\n",
    "\n",
    "* 이전의 DNN 구조와 동일하게 합성곱을 거친 후, 활성화함수를 거침으로써,<br>\n",
    "보다 복잡한 특징들을 추출할 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Lm8ure5ino30",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "jMXzlHUWno32",
    "colab_type": "code",
    "outputId": "674fff9b-09bb-4b87-f7a8-14576dd88096",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0., 169.],\n",
       "        [  0., 194.]],\n",
       "\n",
       "       [[  0., 180.],\n",
       "        [  0., 172.]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 활성화 함수를 거침\n",
    "a = relu(outputs)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JNC1LQhno34",
    "colab_type": "text"
   },
   "source": [
    "합성곱 신경망의 한 계층은 DNN과 같이 두단계를 거칩니다.<br>\n",
    "1. 합성곱 연산(with bias)\n",
    "2. 활성화 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYj-55Z0no36",
    "colab_type": "text"
   },
   "source": [
    "<br>\n",
    "## 3. 합성곱 층의 Notation\n",
    "---\n",
    "\n",
    "* 이후 논문과 모델 구조를 보면서 빠르게 이해할 수 있도록, 주요 Notation을 정리하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBIdCF7Lno37",
    "colab_type": "text"
   },
   "source": [
    "$\n",
    "f^{[l]} = \\mbox{filter size} \\\\\n",
    "p^{[l]} = \\mbox{padding} \\\\\n",
    "s^{[l]} = \\mbox{stride} \\\\\n",
    "k^{[l]} = \\mbox{number of filters}\\\\\n",
    "----\\\\\n",
    "\\mbox{input shape : } (n_h^{[l-1]},n_w^{[l-1]},n_c^{[l-1]}) \\\\\n",
    "\\mbox{filter shape : } ( f^{[l]}_h,f^{[l]}_w,n_c^{[l-1]},k^{[l]}) \\\\\n",
    "\\mbox{output shape : } (n_h^{[l]},n_w^{[l]},n_c^{[l]})\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsDm5Ibyno37",
    "colab_type": "text"
   },
   "source": [
    "### (1) 출력 층의 크기 (output shape)\n",
    "\n",
    "출력 층의 높이와 폭은 아래의 수식 구조를 따릅니다.\n",
    "\n",
    "$\n",
    "n_h^{[l]} = \\lfloor \\frac{n_h^{[l-1]}+2p^{[l]}-f_h^{[l]}}{s^{[l]}}+1\\rfloor\n",
    "$<br>\n",
    "$\n",
    "n_w^{[l]} = \\lfloor \\frac{n_w^{[l-1]}+2p^{[l]}-f_h^{[l]}}{s^{[l]}}+1\\rfloor\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5BJ9ZJlno38",
    "colab_type": "text"
   },
   "source": [
    "### (2) 출력 값의 채널 수\n",
    "\n",
    "출력 층의 채널의 수($n_c^{[l]}$)는 필터의 갯수($k^{[l]}$)와 동일합니다.\n",
    "\n",
    "$\n",
    "n_c^{[l]} = k^{[l]}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUNV9Hunno38",
    "colab_type": "text"
   },
   "source": [
    "### (3) 파라미터의 수 \n",
    "\n",
    "각 합성곱 층은 Filter 내 Weight와 Bias로 이루어져 있습니다.<br>\n",
    "$\n",
    "\\mbox{#parameter} = \\mbox{#weights} + \\mbox{#bias} \\\\\n",
    "\\mbox{#weights} = f_h^{[l]} * f_w^{[l]} * n_c^{l-1} * k^{[l]} \\\\\n",
    "\\mbox{#bias} = n_c^{[l]}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHYjFNTmno39",
    "colab_type": "text"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "# \\[ 2. CNN 모델 분석하기 \\]\n",
    "\n",
    "----\n",
    "----\n",
    " \n",
    "> *고전 모델 중 하나인 LeNet-5을 각 단계별로 출력 값의 크기 및 파라미터의 수를 계산해보도록 하겠습니다.*<br>\n",
    "\n",
    "\n",
    "간단한 CNN 모델의 구성을 통해 계산해보기\n",
    "----\n",
    "![Imgur](https://i.imgur.com/DHpS6r8.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w76KPf8zno39",
    "colab_type": "text"
   },
   "source": [
    "각 층 별 필터의 크기, 스트라이드, 패딩은 아래와 같습니다.\n",
    "\n",
    "| Layer | # filters | filter size | stride | padding |\n",
    "| ----- | -------   | ------ | ----- | ----- |\n",
    "|  C1   | 6 | (5,5) | 1 | 0 |\n",
    "|  S2   | 6 | (2,2) | 2 | 0 |\n",
    "|  C3   | 16 | (5,5) | 1 | 0 |\n",
    "|  S4   | 16 | (2,2) | 2 | 0 |\n",
    "|  C5   | 120 | (5,5) | 1 | 0 |\n",
    "|  F6   | 84 | --- | --- | --- |\n",
    "|  OUTPUT   | 10 | --- | --- | --- |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QzRFAkSno3-",
    "colab_type": "text"
   },
   "source": [
    "## 1. 각 층 별 출력 층의 크기 계산하기\n",
    "----\n",
    "\n",
    "출력층은 아래의 수식을 따릅니다.<br>\n",
    "$\n",
    "n_h^{[l]} = \\lfloor \\frac{n_h^{[l-1]}+2p^{[l]}-f_h^{[l]}}{s^{[l]}}+1\\rfloor\n",
    "$<br>\n",
    "$\n",
    "n_w^{[l]} = \\lfloor \\frac{n_w^{[l-1]}+2p^{[l]}-f_h^{[l]}}{s^{[l]}}+1\\rfloor\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlsyzaDWno3_",
    "colab_type": "text"
   },
   "source": [
    "#### 예제) 각 층 별 출력 층의 크기 계산하기 \n",
    "\n",
    "| Layer | FEATURE MAP SIZE |\n",
    "| ----- | -------   | \n",
    "| INPUT | (32,32,1) |\n",
    "|  C1   | ? |\n",
    "|  S2   | ? |\n",
    "|  C3   | ? |\n",
    "|  S4   | ? |\n",
    "|  C5   | ? |\n",
    "|  F6   | ? |\n",
    "|OUTPUT | ? |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xS2lCgano3_",
    "colab_type": "text"
   },
   "source": [
    "#### 정답 :\n",
    "\n",
    "| Layer | FEATURE MAP SIZE |\n",
    "| ----- | -------   | \n",
    "| INPUT | (32,32,1) |\n",
    "|  C1   | (28,28,6) |\n",
    "|  S2   | (14,14,6) |\n",
    "|  C3   | (10,10,16) |\n",
    "|  S4   | (5,5,16) |\n",
    "|  C5   | (1,1,120)|\n",
    "|  F6   | (84,) |\n",
    "|  OUTPUT   | (10,) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tC8f_b3kno4A",
    "colab_type": "text"
   },
   "source": [
    "## 2. 각 층 별 파라미터의 수 계산하기\n",
    "----\n",
    "\n",
    "각 합성곱 층은 Filter 내 Weight와 Bias로 이루어져 있습니다.<br>\n",
    "$\n",
    "\\mbox{#parameter} = \\mbox{#weights} + \\mbox{#bias} \\\\\n",
    "\\mbox{#weights} = f_h^{[l]} * f_w^{[l]} * n_c^{l-1} * k^{[l]} \\\\\n",
    "\\mbox{#bias} = n_c^{[l]}\n",
    "$<br>\n",
    "풀링층은 별도로 학습하는 파라미터가 없습니다.\n",
    "\n",
    "#### Caution\n",
    "* sub-sampling은 Max-Pooling으로 생각하고 계산해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DU0xq8NEno4B",
    "colab_type": "text"
   },
   "source": [
    "#### 예제) 각 층 별 출력 층의 크기 계산하기 \n",
    "\n",
    "| Layer | # Parameter |\n",
    "| ----- | -------   | \n",
    "| INPUT | 0 |\n",
    "|  C1   | $(5*5*1*6) + 6 = 156 $ |\n",
    "|  S2   | ? |\n",
    "|  C3   | ? |\n",
    "|  S4   | ? |\n",
    "|  C5   | ? |\n",
    "|  F6   | ? |\n",
    "|OUTPUT | ?|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGwBZtsEno4B",
    "colab_type": "text"
   },
   "source": [
    "#### 정답 :\n",
    "\n",
    "| Layer | # Parameter |\n",
    "| ----- | -------   | \n",
    "| INPUT | 0 |\n",
    "|  C1   | $(5*5*1*6) + 6 = 156 $ |\n",
    "|  S2   | $0$ |\n",
    "|  C3   | $(5*5*6*16) + 16 = 2,416 $ |\n",
    "|  S4   | $0$ |\n",
    "|  C5   | $(5*5*16*120)+120 = 48,120$ |\n",
    "|  F6   | $120*84 + 84 = 10,164 $ |\n",
    "|OUTPUT | $84*10 + 10 = 850$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhdlsrmqxQ1t",
    "colab_type": "text"
   },
   "source": [
    "# \\[ 3.간단한 Convolution Neural Network 만들기 \\]\n",
    "\n",
    "----\n",
    "----\n",
    " \n",
    "> *자신만의 Convolution Neural Network 을 생성해보고 결과를 확인해 봅니다.*<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "sfj0fizJvrFU",
    "colab_type": "code",
    "outputId": "77d309b7-87eb-4585-a335-896105a313fb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "rtfy0Chnxi8u",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "xs_flat = #fix me#\n",
    "xs = #fix me#\n",
    "ys = #fix me#\n",
    "ys_cls = #fix me#\n",
    "\n",
    "with #fix me# : scope name is layer_1\n",
    "    kernel_init = #fix me # random normal \n",
    "    kernel= # fix me #\n",
    "           \n",
    "    bias_init = tf.random.normal(#fix me#)\n",
    "    bias = tf.Variable(#fix me#)\n",
    "\n",
    "    layer = tf.nn.conv2d(#fix me#) # convolution and add bias        \n",
    "    layer = #fix me# # apply activation function \n",
    "    \n",
    "with #fix me #  : scope name is layer_2\n",
    "    kernel_init = #fix me # random normal \n",
    "    kernel = # fix me # \n",
    "    bias_init = # fix me # \n",
    "    bias=# fix me # \n",
    "    \n",
    "    layer = # fix me # \n",
    "    layer = # fix me # apply activation funciton \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "with tf.name_scope('FC'):\n",
    "    flat_layer = #fix me# flatten layer \n",
    "    logits = #fully connected layer # \n",
    "    logits_cls = #onehot to number #\n",
    "    \n",
    "    loss = #fix me #\n",
    "acc = #fix me #\n",
    "lr = 0.0001\n",
    "train_op = #fix me# Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "pA9gS-Kl0dsT",
    "colab_type": "code",
    "outputId": "af8ee335-4063-4c4c-bb9d-b69c7933efeb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4300566 0.0966\n",
      "0.2663954 0.5106\n",
      "0.16920345 0.65826666\n",
      "0.122966625 0.7353\n",
      "0.09534456 0.78292\n",
      "0.08291871 0.81523335\n",
      "0.0698219 0.8387714\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-98e93fab7e9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     _, loss_ = sess.run([train_op, loss],\n\u001b[0;32m----> 9\u001b[0;31m                         {xs_flat: batch_xs, ys: batch_ys})\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.group(#fix me #) # global , local intializer\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(30000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(120)\n",
    "    _, loss_ = sess.run(#fix me#)\n",
    "    \n",
    "    if i % 1000 ==0:\n",
    "        val_loss, val_acc = sess.run(#fix me#)\n",
    "        print(val_loss, val_acc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZCsX4Cjno4C",
    "colab_type": "text"
   },
   "source": [
    "#  \n",
    "\n",
    "---\n",
    "\n",
    "    Copyright(c) 2019 by Public AI. All rights reserved.<br>\n",
    "    Writen by PAI, SangJae Kang ( rocketgrowthsj@publicai.co.kr )  last updated on 2019/04/26\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "배포_4_합성곱 신경망의 층.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}