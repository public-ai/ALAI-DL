{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "╔══<i><b>Alai-DeepLearning</b></i>════════════════════════════╗\n",
    "###  &nbsp;&nbsp; **✎&nbsp;&nbsp;Week 11. CNN Architectures**\n",
    "# Section 1. GoogLeNet의 여러 직관들\n",
    "\n",
    "\n",
    "### _Objective_\n",
    "\n",
    "1. GoogleNet은 VGGNet과 비슷한 시기에 나온 Network로, VGG Network와는 다른 방식으로 접근한 모델입니다.<br>\n",
    "2. GoogleNet의 핵심인 Inception Module에 대해 배워보도록 하겠습니다.\n",
    "\n",
    "╚═════════════════════════════════════════╝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# \\[ 1x1 Convolution \\]\n",
    "---\n",
    "---\n",
    "\n",
    "> *GoogLeNet은 이전 연구인 Network In Network라는 연구의 1x1 Convolution에서 영감을 받아, 발전시킨 모델입니다.* <br>\n",
    "\n",
    "reference : [Network in Network](https://arxiv.org/pdf/1312.4400.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. 1x1 Convolution이란? \n",
    "---\n",
    "\n",
    "![Imgur](https://i.imgur.com/whARKbB.png)\n",
    "\n",
    "* CNN 모델에서 Convolution Layer는 보통 (3,3)이상의 필터 크기를 가집니다.<br> 주위 픽셀간의 공간 정보를 활용하기 때문입니다.<br>\n",
    "* 이와 달리, 1x1 Convolution Layer는 주위 값들의 정보를 이용하지 않고, 각 점에 해당하는 Receptive Field의 정보만을 이용하게 됩니다.<br>\n",
    "* 즉 아래의 과정과 동일합니다.<br>\n",
    "\n",
    "![Imgur](https://i.imgur.com/ZBVsMeT.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. 1x1 Convolution이 가지는 장점\n",
    "---\n",
    "\n",
    "* 1x1 Convolution을 이용하면, 연산량을 크게 줄일 수 있는 장점이 있습니다.<br>\n",
    "예제를 통해 확인해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](https://i.imgur.com/e0Raylv.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 Input Layer의 크기가 (32,32,100)이고, 3x3 Convolution의 Filter 갯수가 200개일 때, 총 Weight의 갯수는 몇개일까요? \n",
    "\n",
    "> $3 * 3 * 100 * 200 = 180,000$ 개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](https://i.imgur.com/OfgnaJz.png)\n",
    "\n",
    "위와 같이 Input Layer의 크기가 (32,32,100)이고, 1x1 Convolution의 Filter 갯수가 20개이고, 3x3 Convolution의 Filter 갯수가 200개일 때, 총 Weight의 갯수는 몇개일까요? \n",
    "\n",
    "> $(1 * 1 * 100 * 20) + (3 * 3 * 20 * 200)= 38,000$개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 대비 Weight의 갯수가 20% 수준으로 매우 크게 떨어졌습니다.<br> \n",
    "그리고 1x1 Convolution이 추가됨으로써, 비선형성 증대되었습니다.<br>\n",
    "1x1 Convolution은 이후 많은 네트워크에서 모델을 경량화시키고, 연산량을 줄이기 위해 <br>\n",
    "많이 이용하는 기법이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# \\[ 2. Inception Module \\]\n",
    "---\n",
    "---\n",
    "\n",
    "> *GoogLeNet 팀은 적정한 수준의 Filter Size를 사람이 결정하는 것이 아닌, 모델이 학습할 수 있도록 Inception Module을 제안하였습니다.* <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Inception Module이란?\n",
    "----\n",
    "\n",
    "* Inception 팀에서는 어떻게 하면 적절한 수준의 Sparse Connection을 할 수 있을지를 고민하였습니다.<br> \n",
    "* Convolution 연산은 기본적으로 특정 입력만을 연결하는 대표적인 Sparse Connection입니다.<br> 하지만 고정된 크기의 Filter를 가지고 있기 때문에 유연하게 원하는 입력과 연결할 수 없다는 한계를 가지고 있었습니다.\n",
    "* 이를 개선하기 위해, inception Module은 1x1 convolution , 3x3 Convolution , 5x5 Convolution, max pooling을 병렬적으로 연결합니다.\n",
    "\n",
    "![Imgur](https://i.imgur.com/9Hg6ElP.png)\n",
    "\n",
    "결과적으로 이러한 형태의 Feature 추출 과정은 최대한 모델이 원하는 대로 입력간의 연결을 형성할 수 있도록 했습니다. 하지만 이렇게 단순히 구성할 경우 연산량이 너무 많아지게 됩니다. 특히 3x3 Convolution, 5x5 Convolution의 연산량은 매우 커지게 됩니다.\n",
    "\n",
    "![Imgur](https://i.imgur.com/wnzbIol.png)\n",
    "\n",
    "위에서 배운 1x1 Convolution 연산을 앞에 붙이게 됨으로써, 연산량을 줄이게 됩니다. <br>\n",
    "이러한 Block들을 쭉 이어붙인 형태가 바로 GoogLeNet입니다.\n",
    "\n",
    "![Imgur](https://i.imgur.com/n2EUKpq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "---\n",
    "\n",
    "    Copyright(c) 2019 by Public AI. All rights reserved.<br>\n",
    "    Writen by PAI, SangJae Kang ( rocketgrowthsj@publicai.co.kr )  last updated on 2019/05/14\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}